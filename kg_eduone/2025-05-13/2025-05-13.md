
https://blog.naver.com/winddori2002/221992543837

CNN  RNN - LSTM - GRU - TransFormer - Google Engineer (LLM)

LLM - chatgpt & Llama ~ pretraining - Fine tuning 



### **1. RNN이란?**

**RNN**이란 Recurrent Neural Network의 약자로, **순환 신경망**을 뜻합니다.

RNN은 **입력과 출력을 시퀀스 단위로 처리**합니다. 

시퀀스란 문장 같은 단어가 나열된 것을 뜻합니다.

이러한 시퀀스들을 처리하기 위해 고안된 모델을 시퀀스 모델이라 하며, 그중에서 RNN은 딥 러닝의 가장 기본적인 시퀀스 모델입니다.

RNN의 은닉층에서 활성화 함수를 통해 결과를 내보내는 역할을 하는 노드를 셀이라고 합니다.

이 셀은 이전의 값을 기억하려고 하는 일종의 메모리 역할을 수해하므로 **메모리 셀**이라고 부릅니다.

RNN은 이름에서 알 수 있듯이, **은닉층의 메모리 셀에서 나온 값이 다음 은닉층의 메모리 셀에 입력됩니다.**

**이 값을 은닉 상태라고 합니다.**

장단기 메모리(Long Short-Term Memory, **LSTM**)는 순환 신경망(RNN) 기법의 하나로 셀, 입력 게이트, 출력 게이트, 망각 게이트를 이용해 기존 순환 신경망(RNN)의 문제인 기울기 소멸 문제(vanishing gradient problem)를 방지하도록 개발되었다





대규모 언어 모델(LLM)은 **텍스트를 인식하고 생성하는 등의 작업을 수행할 수 있는 일종의 인공 지능(AI) 프로그램**입니다. LLM은 방대한 데이터 세트를 학습하므로 "대규모"라는 이름이 붙었습니다. LLM은 머신 러닝, 특히 트랜스포머 모델이라고 하는 일종의 신경망을 기반으로 합니다.




![[Pasted image 20250513091204.png]]

![[Pasted image 20250513094846.png]]

![[Pasted image 20250513095041.png]]

![[Pasted image 20250513095246.png]]

![[Pasted image 20250513095259.png]]

![[Pasted image 20250513095350.png]]

![[Pasted image 20250513095510.png]]
보편적으로 1,2번 방식을 사용
방법3 은 권장되지 않음 - 어노말리 현상 발생 가능 - 정규화 단계에서 배울 예정!

![[Pasted image 20250513102224.png]]

![[Pasted image 20250513102450.png]]

![[Pasted image 20250513102517.png]]

![[Pasted image 20250513102624.png]]

![[Pasted image 20250513102700.png]]

![[Pasted image 20250513102838.png]]

![[Pasted image 20250513102900.png]]



---------------------------------



![[Pasted image 20250513103659.png]]

![[Pasted image 20250513111723.png]]

![[Pasted image 20250513111942.png]]

![[Pasted image 20250513111955.png]]

![[Pasted image 20250513112022.png]]

![[Pasted image 20250513112223.png]]

![[Pasted image 20250513112512.png]]

![[Pasted image 20250513112631.png]]

![[Pasted image 20250513112828.png]]

![[Pasted image 20250513112956.png]]

![[Pasted image 20250513113112.png]]

![[Pasted image 20250513113236.png]]
이렇게 테이블을 나눠 이상현상이 일어나지 않게 분류하는 것이 정규화

![[Pasted image 20250513113643.png]]

![[Pasted image 20250513113707.png]]

![[Pasted image 20250513113716.png]]

![[Pasted image 20250513113851.png]]

![[Pasted image 20250513113927.png]]



![[Pasted image 20250513114022.png]]

![[Pasted image 20250513115055.png]]

![[Pasted image 20250513115533.png]]

![[Pasted image 20250513115648.png]]

![[Pasted image 20250513115748.png]]

![[Pasted image 20250513115849.png]]
여기까지!

-------------------------------------------------



### 자바

![[Pasted image 20250513140322.png]]

![[Pasted image 20250513140441.png]]

![[Pasted image 20250513140553.png]]

![[Pasted image 20250513140709.png]]

![[Pasted image 20250513141655.png]]

![[Pasted image 20250513144212.png]]

![[Pasted image 20250513150955.png]]







![[Pasted image 20250513153119.png]]

![[Pasted image 20250513153132.png]]




![[Pasted image 20250513153322.png]]

![[Pasted image 20250513153356.png]]































































































































































































































